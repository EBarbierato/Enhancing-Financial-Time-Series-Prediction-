{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1930,"status":"ok","timestamp":1706710733960,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"tpGorwCIdm2i"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1706710733960,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"xnWrEsMFcUtj"},"outputs":[],"source":["# First, let's reload the original datasets since the previous dataframes have been altered through oversampling\n","orig_data = pd.read_csv('/Users/filippoorlandi/Desktop/ARTICLE/Instructions_Article/BRASILE /fake_original_BRAZIL.csv')\n","false_data = pd.read_csv('/Users/filippoorlandi/Desktop/ARTICLE/Instructions_Article/BRASILE /original_log_br.csv')\n","\n","# Rename the columns for clarity\n","orig_data.rename(columns={'0': 'Log_Return'}, inplace=True)\n","false_data.rename(columns={'0': 'Log_Return'}, inplace=True)\n","orig_data.drop(orig_data.tail(1).index, inplace=True)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1706710733960,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"Rh-fsR7Ndoti","outputId":"fe046134-c22f-4dd2-ae2e-1b5806a31396"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Log_Return</th>\n","      <th>Fake_Log_Return</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.020506</td>\n","      <td>-0.065855</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.018665</td>\n","      <td>0.024553</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.004328</td>\n","      <td>-0.008531</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.017426</td>\n","      <td>0.012463</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.012386</td>\n","      <td>0.042790</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2294</th>\n","      <td>0.015233</td>\n","      <td>0.021954</td>\n","    </tr>\n","    <tr>\n","      <th>2295</th>\n","      <td>-0.005720</td>\n","      <td>-0.027134</td>\n","    </tr>\n","    <tr>\n","      <th>2296</th>\n","      <td>0.013064</td>\n","      <td>0.042732</td>\n","    </tr>\n","    <tr>\n","      <th>2297</th>\n","      <td>-0.017426</td>\n","      <td>-0.001151</td>\n","    </tr>\n","    <tr>\n","      <th>2298</th>\n","      <td>-0.023683</td>\n","      <td>-0.010342</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2299 rows × 2 columns</p>\n","</div>"],"text/plain":["      Log_Return  Fake_Log_Return\n","0       0.020506        -0.065855\n","1      -0.018665         0.024553\n","2       0.004328        -0.008531\n","3      -0.017426         0.012463\n","4       0.012386         0.042790\n","...          ...              ...\n","2294    0.015233         0.021954\n","2295   -0.005720        -0.027134\n","2296    0.013064         0.042732\n","2297   -0.017426        -0.001151\n","2298   -0.023683        -0.010342\n","\n","[2299 rows x 2 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.DataFrame(orig_data)\n","df ['Fake_Log_Return'] = false_data\n","df"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":723,"status":"ok","timestamp":1706710737069,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"ZQvc-zYad76P","outputId":"decfe33c-d08c-49f3-af97-d70d923b9a68"},"outputs":[{"data":{"text/plain":["0      -0.065855\n","1       0.024553\n","2      -0.008531\n","3       0.012463\n","4       0.042790\n","          ...   \n","2294    0.021954\n","2295   -0.027134\n","2296    0.042732\n","2297   -0.001151\n","2298   -0.010342\n","Name: Fake_Log_Return, Length: 2299, dtype: float64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df ['Fake_Log_Return']"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3972,"status":"ok","timestamp":1706710754626,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"fxZ0z7hb3xHi","outputId":"211ac53d-f556-4036-9a60-f09656dae3bf"},"outputs":[{"data":{"text/plain":["((2266, 10, 2), (23, 10, 2), (2266,), (23,))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","import numpy as np\n","def prepare_lstm_data_with_extra_feature(df, n_steps, feature_name):\n","    X, y = [], []\n","    for i in range(len(df) - n_steps):\n","        # Extract the sequence of log returns\n","        log_returns_sequence = df['Log_Return'][i:i + n_steps].values.reshape(-1, 1)\n","        # Extract the corresponding sequence of the extra feature\n","        extra_feature_sequence = df[feature_name][i:i + n_steps].values.reshape(-1, 1)\n","        # Combine the sequences\n","        sequence_combined = np.hstack((log_returns_sequence, extra_feature_sequence))\n","        X.append(sequence_combined)\n","        y.append(df['Log_Return'][i + n_steps])\n","    return np.array(X), np.array(y)\n","\n","# Example usage:\n","# Let's say the extra feature is in a column named 'Extra_Feature'\n","n_steps = 10\n","feature_name = 'Fake_Log_Return'\n","\n","# Normalize both 'Log_Return' and 'Extra_Feature'\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","prova_log_returns = df['Log_Return'].values.reshape(-1, 1)\n","extra_feature = df[feature_name].values.reshape(-1, 1)\n","\n","prova_scaled = scaler.fit_transform(prova_log_returns)\n","extra_feature_scaled = scaler.fit_transform(extra_feature)\n","\n","# Combine the scaled features into a single DataFrame\n","combined_df = pd.DataFrame({\n","    'Log_Return': prova_scaled.flatten(),\n","    'Fake_Log_Return': extra_feature_scaled.flatten()\n","})\n","\n","# Prepare data for LSTM\n","X_prova, y_prova = prepare_lstm_data_with_extra_feature(combined_df, n_steps, feature_name)\n","\n","# Split the data into training and testing sets\n","X_train_prova, X_test_prova, y_train_prova, y_test_prova = train_test_split(X_prova, y_prova, test_size=0.01, random_state=42)\n","\n","X_train_prova.shape, X_test_prova.shape, y_train_prova.shape, y_test_prova.shape\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VJ79XMIbrDbh"},"outputs":[],"source":["from keras.models import Sequential\n","from keras.layers import LSTM, Dense, Dropout\n","\n","def create_lstm_model(input_shape):\n","    model = Sequential()\n","    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n","    model.add(Dropout(0.2))\n","    model.add(LSTM(units=100))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1))\n","    model.compile(optimizer='adam', loss='mean_squared_error')\n","    return model\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153305,"status":"ok","timestamp":1706699400369,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"O9B1_ROjrJqq","outputId":"96e7537b-b958-4c23-c527-c72bb09429a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n"]},{"name":"stderr","output_type":"stream","text":["/Users/filippoorlandi/Desktop/ARTICLE/Instructions_Article/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0699 - val_loss: 0.0015\n","Epoch 2/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0071 - val_loss: 0.0017\n","Epoch 3/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0013\n","Epoch 4/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0065 - val_loss: 0.0015\n","Epoch 5/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0013\n","Epoch 6/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0064 - val_loss: 0.0013\n","Epoch 7/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0066 - val_loss: 0.0014\n","Epoch 8/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0061 - val_loss: 0.0012\n","Epoch 9/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0068 - val_loss: 0.0012\n","Epoch 10/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0012\n","Epoch 11/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0067 - val_loss: 0.0012\n","Epoch 12/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0012\n","Epoch 13/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0014\n","Epoch 14/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0013\n","Epoch 15/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0020\n","Epoch 16/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0013\n","Epoch 17/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0061 - val_loss: 0.0013\n","Epoch 18/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0057 - val_loss: 0.0021\n","Epoch 19/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0058 - val_loss: 0.0016\n","Epoch 20/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0058 - val_loss: 0.0016\n","Epoch 21/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0012\n","Epoch 22/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0013\n","Epoch 23/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0064 - val_loss: 0.0016\n","Epoch 24/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0012\n","Epoch 25/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0020\n","Epoch 26/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0012\n","Epoch 27/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0014\n","Epoch 28/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0016\n","Epoch 29/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0062 - val_loss: 0.0020\n","Epoch 30/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0012\n","Epoch 31/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0061 - val_loss: 0.0012\n","Epoch 32/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0013\n","Epoch 33/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0062 - val_loss: 0.0013\n","Epoch 34/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0018\n","Epoch 35/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0061 - val_loss: 0.0012\n","Epoch 36/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0012\n","Epoch 37/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0012\n","Epoch 38/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0061 - val_loss: 0.0014\n","Epoch 39/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0016\n","Epoch 40/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0012\n","Epoch 41/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0012\n","Epoch 42/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0013\n","Epoch 43/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0058 - val_loss: 0.0019\n","Epoch 44/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0059 - val_loss: 0.0013\n","Epoch 45/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0013\n","Epoch 46/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0047 - val_loss: 0.0012\n","Epoch 47/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0051 - val_loss: 0.0013\n","Epoch 48/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0057 - val_loss: 0.0012\n","Epoch 49/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0012\n","Epoch 50/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0025\n","Epoch 51/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0012\n","Epoch 52/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0059 - val_loss: 0.0012\n","Epoch 53/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0012\n","Epoch 54/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0012\n","Epoch 55/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0012\n","Epoch 56/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0053 - val_loss: 0.0012\n","Epoch 57/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0056 - val_loss: 0.0012\n","Epoch 58/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0052 - val_loss: 0.0012\n","Epoch 59/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0013\n","Epoch 60/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0013\n","Epoch 61/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0049 - val_loss: 0.0012\n","Epoch 62/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0050 - val_loss: 0.0013\n","Epoch 63/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0052 - val_loss: 0.0016\n","Epoch 64/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0012\n","Epoch 65/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0012\n","Epoch 66/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0012\n","Epoch 67/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0020\n","Epoch 68/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0055 - val_loss: 0.0013\n","Epoch 69/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0015\n","Epoch 70/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0012\n","Epoch 71/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0012\n","Epoch 72/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0012\n","Epoch 73/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0012\n","Epoch 74/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0012\n","Epoch 75/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0012\n","Epoch 76/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0057 - val_loss: 0.0012\n","Epoch 77/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0060 - val_loss: 0.0012\n","Epoch 78/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0049 - val_loss: 0.0012\n","Epoch 79/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0051 - val_loss: 0.0012\n","Epoch 80/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0052 - val_loss: 0.0012\n","Epoch 81/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0057 - val_loss: 0.0012\n","Epoch 82/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0054 - val_loss: 0.0013\n","Epoch 83/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0012\n","Epoch 84/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0048 - val_loss: 0.0012\n","Epoch 85/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0056 - val_loss: 0.0012\n","Epoch 86/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0054 - val_loss: 0.0013\n","Epoch 87/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0012\n","Epoch 88/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0047 - val_loss: 0.0012\n","Epoch 89/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0052 - val_loss: 0.0012\n","Epoch 90/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0054 - val_loss: 0.0012\n","Epoch 91/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0055 - val_loss: 0.0012\n","Epoch 92/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0050 - val_loss: 0.0012\n","Epoch 93/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0012\n","Epoch 94/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0055 - val_loss: 0.0012\n","Epoch 95/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0051 - val_loss: 0.0012\n","Epoch 96/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0053 - val_loss: 0.0014\n","Epoch 97/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0050 - val_loss: 0.0012\n","Epoch 98/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0053 - val_loss: 0.0012\n","Epoch 99/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0051 - val_loss: 0.0013\n","Epoch 100/100\n","\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0046 - val_loss: 0.0013\n"]}],"source":["input_shape = (10,2)\n","#input_shape= (X_train_prova[1],X_train_prova[2])\n","model = create_lstm_model(input_shape)\n","history = model.fit(X_train_prova, y_train_prova, epochs=100, batch_size=32, validation_data=(X_test_prova, y_test_prova))\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":975,"status":"ok","timestamp":1706699401302,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"Wmjd1K9GrNbv","outputId":"4c0e8d9e-8ddb-460f-dffa-80c5228ccbab"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n"]}],"source":["predicted_prova = model.predict(X_test_prova)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1706699401302,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"XAHOFHaStKF5","outputId":"159622bc-dcad-4585-8118-d80ca6e73229"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Squared Error for Prova dataset: 8.384752812069052e-05\n"]}],"source":["from sklearn.metrics import mean_squared_error\n","predicted_prova = predicted_prova.reshape(-1, 1)\n","y_test_prova = y_test_prova.reshape(-1, 1)\n","\n","# Inverse transform the predictions and actual values to their original scale\n","predicted_prova_inversed = scaler.inverse_transform(predicted_prova)\n","y_test_prova_inversed = scaler.inverse_transform(y_test_prova)\n","\n","# Calculate MSE\n","mse_prova = mean_squared_error(y_test_prova_inversed, predicted_prova_inversed)\n","print(\"Mean Squared Error for Prova dataset:\", mse_prova)\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1706699402264,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"6ZnaLzXE3jbd","outputId":"8b00d8f5-982d-4ce6-ad9b-6e5db2ba9f3c"},"outputs":[{"data":{"text/plain":["0.009156829588929266"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["from math import sqrt\n","rmse = sqrt (mse_prova)\n","rmse"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1706699402265,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"1gJUkOq_FmLU","outputId":"618a5856-1f02-432b-8062-ae9703815c8a"},"outputs":[{"data":{"text/plain":["0.006495735242507234"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import mean_absolute_error\n","mean_absolute_error(y_test_prova_inversed, predicted_prova_inversed)"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":567,"status":"ok","timestamp":1706699402822,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"suiJIqOREqLM","outputId":"10d5aef8-6551-47b7-9404-57b97f4612e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"]}],"source":["# Generate predictions for the training set\n","predicted_train_prova = model.predict(X_train_prova)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1706699402822,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"toW_PS1WEb1D","outputId":"76f105f5-a6b5-4dc4-8b11-8b48271bdf53"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE for Extreme Values: 0.058535355791874286\n"]}],"source":["from sklearn.metrics import mean_squared_error\n","import numpy as np\n","# Inverse transform the predictions and actual values to their original scale\n","predicted_train_prova_inv = scaler.inverse_transform(predicted_train_prova)\n","y_train_prova_inv = scaler.inverse_transform(y_train_prova.reshape(-1, 1))\n","\n","# Calculate mean and standard deviation of the actual values\n","mu = np.mean(y_train_prova_inv)\n","sigma = np.std(y_train_prova_inv)\n","\n","# Identify indices of extreme values\n","extreme_indices = np.where((y_train_prova_inv < (mu - 2 * sigma)) | (y_train_prova_inv > (mu + 2 * sigma)))[0]\n","\n","# Filter actual and predicted values for extreme values\n","actual_extreme_values = y_train_prova_inv[extreme_indices]\n","predicted_extreme_values = predicted_train_prova_inv[extreme_indices]\n","\n","# Calculate RMSE for extreme values\n","rmse_extreme = np.sqrt(mean_squared_error(actual_extreme_values, predicted_extreme_values))\n","\n","print(f'RMSE for Extreme Values: {rmse_extreme}')\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1706699402822,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"i3K3g32JMbVz","outputId":"5c781a8c-31ac-4740-c948-3e3323bfdd60"},"outputs":[{"data":{"text/plain":["0.05522512674588524"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["mean_absolute_error(actual_extreme_values, predicted_extreme_values)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1706699402823,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"fkaEiq21EwE8","outputId":"11b56cab-2130-40ee-af9d-60cecf6e18f2"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE for Extreme Values: 0.023469199428921304\n"]}],"source":["# Calculate mean and standard deviation of the actual values\n","mu = np.mean(y_test_prova_inversed)\n","sigma = np.std(y_test_prova_inversed)\n","# Identify indices of extreme values\n","extreme_indices = np.where((y_test_prova_inversed < (mu - 2 * sigma)) | (y_test_prova_inversed > (mu + 2 * sigma)))[0]\n","\n","# Filter actual and predicted values for extreme values\n","actual_extreme_values = y_test_prova_inversed[extreme_indices]\n","predicted_extreme_values = predicted_prova_inversed[extreme_indices]\n","\n","# Calculate RMSE for extreme values\n","rmse_extreme = np.sqrt(mean_squared_error(actual_extreme_values, predicted_extreme_values))\n","\n","print(f'RMSE for Extreme Values: {rmse_extreme}')"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1706699402823,"user":{"displayName":"filippo orlandi","userId":"01023501393725364481"},"user_tz":-60},"id":"ew81QlRgFgAV","outputId":"96dd33b6-e8fe-4350-df21-4c45a1b3d7fa"},"outputs":[{"data":{"text/plain":["0.02342549770831647"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["mean_absolute_error(actual_extreme_values, predicted_extreme_values)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNp8tsXoZf+sJC0tG4O3s00","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
